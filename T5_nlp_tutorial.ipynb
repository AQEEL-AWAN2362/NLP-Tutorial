{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk36xauumDI0"
   },
   "source": [
    "#**T5 stands** for Text-To-Text Transfer Transformer.\n",
    "\n",
    "🔹 What it is:\n",
    "T5 is a transformer-based NLP model from Google. Its main idea is: convert every NLP problem into a text-to-text format.\n",
    "\n",
    "Input: always text\n",
    "\n",
    "Output: always text\n",
    "\n",
    "build of encoder and decoder both.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FXuyvQSm8S3"
   },
   "source": [
    "**1. Text Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403,
     "referenced_widgets": [
      "340c8b4c4a2548db85ae8c0158b82dd6",
      "501f60c65dad442c8d2b13751ff11216",
      "01ae5a0bea7342daa4e908f5d1175481",
      "04d6f5282d074ea9a7b6f4858c4a1794",
      "545f6d3635144d39b2217ce3f8ee4c3b",
      "3a6abd4f3a874cda97d291ab37bff522",
      "4e36118a8bd742b5a22a6f63d53f3f31",
      "1b175ed3074b4f2ab079bd18ee1da084",
      "fee9d4ca114745ad84542a73a9778caf",
      "dba59190ff3d40798f341b08de55d52e",
      "c5a4cb85748c4ac89da12243bd80e6ba",
      "06fdcb942c6046fb88e733157aba84a6",
      "adbccd99715e4e3e96b7d45253b18df6",
      "df5a5c5cfdbc48699bd8cc0ff963edb3",
      "c444aef7d14443b782345a44bac78f62",
      "ae1b7006740749ddbdbbbba5b78871d5",
      "1fad9427e3ed4d018b79473d5837488f",
      "8964a15a3b9e4642a0220d2cb0d2b5af",
      "d720788c43c94fcdb3d57b7d97a8b53b",
      "edad33d14d44451bb4a2b2e655f8954d",
      "b2da4c3a15f54400b0eb96c80b9fde62",
      "c3580ddf76fa4c91a4b51005801f65db",
      "9a9f96fe3112483f95e012d8229ee559",
      "123862f9217a43b792d2f558cc552bab",
      "fb1b2cedec0f4aefb5b126c847beda17",
      "3c3b621383054300b87e174698ea7dd1",
      "5bf3afcbe9904d0d83d83a9308e95e1d",
      "3848ed8b714d4589ab408fdf403501f5",
      "f5cbbb6dc7bd4cf98eb385cb7e83deec",
      "b2d1d62d495a4a59924facda61e740c8",
      "36e433d946724ddeb70db40466e14933",
      "386c12ddca754097bd81efd4c6503252",
      "5d3aed066a4448d0a5c8dcf85d4db65c",
      "8132d05526644b5eae1c8ffcc5a5033d",
      "44642a0b08034bb2a39905dfed57ce27",
      "131c9cf1ba8a480dbb9e4db22b1e47b6",
      "a302212721aa48cda81fbfe335c17589",
      "5a733d3e0be6423aafb73e5a99276af0",
      "e51bf436754642b2970520d22bf337d8",
      "9d1fc1eeece44fd4b77d66c34c24d871",
      "d414ae5ef20348e6953f86c6fb347b70",
      "641baab101f5417f8ed4da21c37349ef",
      "0e2f3a1aff2642439779c26e7ffca543",
      "5ad648d791d14bf5baac1c7ae2790cea",
      "c0d454588fa344b6a9a27cd11c8efb8c",
      "c80110a1c0404ee5be83740c03c1e8b1",
      "09a175a8927148fa80e1f0f70c3966ef",
      "4a0069117dbd401d8c959a8d1832121a",
      "45649c6b00e941bc92e5063793e76efb",
      "a48872e022ec49c083a66a89489404d2",
      "cf22b25d1d8f411fbb50c31fa414202d",
      "bd7c710a2ba14328a7b33a6666f56b2d",
      "697e5f5a74c24d6ca12a26c40c0c8ab4",
      "97ae5e7aeaa94b10a452c6aae5c12fb0",
      "854d560c474c41b19fc7e8468558175d",
      "bb0329740c5b463bb283f3e6d119d164",
      "5f2dc31a3ca048c38abc9c6d0bf9fc45",
      "eafd2b2bf6a24d429ab7caa12bc13e00",
      "85217016fac448bbadf415d8418c80d5",
      "886a96b12b6c4d56859bb14de0084962",
      "a0864648bc6941cf9ade79f58a2c3919",
      "ca1843da0d8149ba89f100a06d347282",
      "20bd835121a143a9bf1d70d92b6172e7",
      "4c9d5934cc654267bbe4d9747add6f11",
      "3c41f882d18245a986f2417ff9041264",
      "ca5af20573ab40dbb67e747415969423"
     ]
    },
    "executionInfo": {
     "elapsed": 48215,
     "status": "ok",
     "timestamp": 1758289190088,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "1s8nBBp3hrHZ",
    "outputId": "64cbc8bb-dbbb-4626-feaa-a435a2408dcd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340c8b4c4a2548db85ae8c0158b82dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fdcb942c6046fb88e733157aba84a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9f96fe3112483f95e012d8229ee559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8132d05526644b5eae1c8ffcc5a5033d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d454588fa344b6a9a27cd11c8efb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0329740c5b463bb283f3e6d119d164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Your max_length is set to 50, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ai is transforming everything almost into automation and cutting the human efforts .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summerizer = pipeline(\"summarization\", model= \"google-t5/t5-small\")\n",
    "text = \"\"\" Hi welcome to the world of Ai. Ai is transforming everything almost\n",
    " into automation and cutting the human efforts on large scale.\"\"\"\n",
    "summary = summerizer(text, max_length=50, min_length=10, do_sample=False)\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8g5jW3F2L7U"
   },
   "source": [
    "**2. AI Content Rewriter / Paraphraser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276,
     "referenced_widgets": [
      "963c094c38864f188878c7c2cf5be666",
      "c0bee320e1b44a0fa9b812a4b7989d54",
      "fd1dfc4d03fb48faa1e4807d32fa9724",
      "7bf2f5278bcf4bbab6e48bb422c88e0a",
      "d056aa448aee47858f4d28bbb85f8512",
      "54efb342228a4c3987a41a8edbdc113c",
      "9f6d3d61c7ac4ea6a5a4a087dfcadeb9",
      "e6a46e62829541fe9a5be50afb943f67",
      "4b046cb91def4226b1c3a3c90b40a7ec",
      "d1eebe8433e041c28fc549b9ca815fcb",
      "eb895d4ba3474a93af91649af047e7ad",
      "846fa101cef548d1add781ef28e58517",
      "97594430350e4bb7a56d08029dda854e",
      "5aec64952b264893bf922bb6ea4d6a1a",
      "901217f9ae544cbe8b030c7896eb04bc",
      "a7e40173dcb24b68bc892484c3bd4327",
      "029b9a9e093e4d37b5e59e79c509142e",
      "81e6f3dadf3a4b278617aa1a05836fcc",
      "a1c44b5915bf474282aadc7ac867b5f0",
      "7036a2b46ad447798f36a9baef8ce158",
      "e3dae1422643495b87c803be29f62128",
      "ffdf95c0d5f447b0b3cf8ce5f9dfe038",
      "0bb83805e41e4d8fb5cfdc48eabf317b",
      "929e00430e5c4bcda649830842771b09",
      "c03cb7cb37e246a7af3af200769d8351",
      "9363df244eb743c8b62f8dfd564f26a1",
      "141f47c774a74f8291e04c6045dcb5dd",
      "16876b549e27466f87b1a87000bcbf03",
      "2faf6c2853c2428fa4761979f7cae56a",
      "4c36816f9104417d84321a39e245e466",
      "69e097dc9e32499e8b7a1b2513208377",
      "fd3482228e474465afeb2224b5a6c2aa",
      "a11c4951b96e43e48e5b9dba332f3673",
      "102db9f3b899456f91a33f78b7c83da2",
      "9a6e2d8de204497eaa63686ba70d0741",
      "0c5f02c9cda74a3fb77018062fd22ecb",
      "00d1ee1994034eef9873b783731e8a33",
      "e0d1f32aa2594be19f9f393b39a96f6e",
      "229ade40aea0450f872bb5eb32221338",
      "74c882423edf44a5a125f86c54db33fa",
      "a350d093d07644b28fc4a4b8574f3b63",
      "a592e44a106c4198b7f458be89948300",
      "92a63be601ab49ed99e9c37093cfc60e",
      "f29cd99e9e25410cb58820bf8d4f31d6",
      "5d677a319ea6454d8fda3bea87000777",
      "9d590b99c6444cd6bde1614f5c359be3",
      "6d6f1e73d5de48ff9744a30fb0b38354",
      "72e99020aed14804a2fbe8e023b473be",
      "041c7624489043a9beddc90e98f6521e",
      "3186fadd6b2a4316b8132ae20703b0f4",
      "adae4c7782cc4bf1b14ae4e1db4d1f56",
      "b70507d7218549538b27fe0c1fa01fc0",
      "43d4ba8224be404a905d77bf5dfd0d4d",
      "1d057af5ce8a409b8bac40ca0e49b2e4",
      "c17fbed0c70f46eb851ca7efb23c83fa",
      "10482b4ddb514d2484395e11eb5e934c",
      "e871599424984ef9918f9ccb7ba54a82",
      "e7bf6795fe3d45cfb7846b4d521e9104",
      "eff615bf223d44d894ee04cc64a4b8a6",
      "d75b82d077d54419b8c18656e77a0f73",
      "6907b4d1f27947088c8566baf2cf5a24",
      "b451a9a221384af6bc80cf2b0aaeb938",
      "1e6df163e3c441c18900dc22ab92842a",
      "472b2e13c24344339e4e54fe0cccf652",
      "c58a45df3f234cfcae738912595c0646",
      "ece736122f8846b1988d1755aecc5f49",
      "4083931e2571441db6522663e3ab1724",
      "f0f60431e45844869250e93518dfb7db",
      "877d17ea7b1a485d94401994e3f6cdb1",
      "9ab71c7453084a51a218d01fa5c29d2b",
      "b5488765917742e2becbdd4ade991cd0",
      "f569d302616c4ed4bc970e2a2e4f8913",
      "fc572ecd13b34a089a348e4725194980",
      "e74f66a6003b4275a862b7b70092898c",
      "b564683ec11046639c825eb71a852138",
      "1eefd369bb854bb89d7b1f2cdec139a3",
      "c4347c3aff834b02934ee042af64a99c"
     ]
    },
    "executionInfo": {
     "elapsed": 20651,
     "status": "ok",
     "timestamp": 1758289210768,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "_HbE15doKRqP",
    "outputId": "e4f9a47c-d189-46f9-e63e-4c85f7b618d8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963c094c38864f188878c7c2cf5be666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846fa101cef548d1add781ef28e58517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb83805e41e4d8fb5cfdc48eabf317b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "102db9f3b899456f91a33f78b7c83da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d677a319ea6454d8fda3bea87000777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10482b4ddb514d2484395e11eb5e934c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4083931e2571441db6522663e3ab1724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ai is transforming everything almost into automation and cutting human efforts on large scale.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "rewriter = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "text = \"\"\"Hi welcome to the world of Ai. Ai is transforming everything almost\n",
    " into automation and cutting the human efforts on large scale.\"\"\"\n",
    "result =  rewriter(text)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYa-6OnYMsLY"
   },
   "source": [
    "**3. Q&A Bot (FAQ Automation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212,
     "referenced_widgets": [
      "53480911bae343fc9a60587dad03e147",
      "c711a36d8d8346208c855ff6797ce814",
      "3fa493826deb4d04ab26b3184091b89f",
      "05502868bb77489db08f5010f13e4906",
      "413661ad136a4178bfa778af18d693fe",
      "48c4cab9119b48089e0016eccfca8ca6",
      "5da48b14ba2a4fd0af25b6635aada8a6",
      "5063a0e027e44e2bb69da65922efa477",
      "fa8a30231d004149a4fc98a6d86f3600",
      "41bc0dcd835a4f4cb8116e8cf0cbf8a7",
      "628d19696e6147f3b13c04106da61116",
      "e6541d1219684ab2ac79f1d573b81126",
      "8914906cae964871b47a6cdeaf952eb8",
      "dd00606dd8f446aabbedf881cbd4f3e1",
      "128bbf730860423a9b0e6fd164efbfea",
      "b6e2fefaa3764052a55aa46e7ae85ddf",
      "34bad9b24e034748b80e05d8085d7e89",
      "1b28ed64987f43a19683b81ae543183e",
      "caafafa3a0ce48b0a96959ff4e4f5fae",
      "6aed29cdca3d4b6fbec543cf15912062",
      "254a7da2641d4d90a0bcaec665ffe095",
      "8a28e4fef2d34d8f83ad810e9982ec9e",
      "9bb8c5a4a3c54003b18cdb8c90f7898c",
      "785046f4b9af4246a7962086f8ad8312",
      "b0d5ef79688a4a8ab8fd87e78367f73a",
      "1d847e8b4cce4ab38b10ae85e5e4f750",
      "fea91ef881994e3d9159b26e6e7d8205",
      "78ca1d7dc7ad4fd18dc155d5e27b2465",
      "52ef9e9c5aa841a38fd7bf90c49034d8",
      "5a5945bdb8dc43278f6104a7536f7d70",
      "045c4c833507462ea8bb829758603bab",
      "0c9d7bebce5844568573ec399995376a",
      "7b3c092bc5ea4b0dabbc65850abf2ab1",
      "83c55f44bcd949f09429f6096c9371f3",
      "a76dc335725740839c84833e2f296a8b",
      "2ce4691cbcef4426a35b5cabe0783c87",
      "bfb4b25bb02240fcbd941bafbc1987b9",
      "9140d377aa5343d89a081153e1f25112",
      "808b8388a6f245f0ae9b94afc2ea7e24",
      "1a73ac29e80340b2a79de2a316ac40cf",
      "530f593cb4384f6c91af81e1e0786099",
      "64d2029450744d9aa3d12bcce480ac74",
      "869032d3138d4138a7ba23ec92baa8e1",
      "c56a2184444b4a54850a234148efacf6",
      "6be5b37c2d984f768e910f31a8f8d665",
      "4cfb7ac4e8914384ad02defe132cb8a2",
      "009dd827f0304b49808f65fc50a22f61",
      "e229890f8ef94a7fa82db378ade64d3c",
      "37cdf97c280a4696b46d4cedf7d0532f",
      "f52ae3e0e8b84c66ae3cc0adaa17a91a",
      "0dfc6e96ccf044b295927c49c484f420",
      "4465e7b7422f44c0af9d10790647f914",
      "75b4d941ccde42edb6fa55326575bcaa",
      "a0f7ea2298f644bea0c51b63c2359cc3",
      "df2d14371e0e4c36bd64e7386bd855a8"
     ]
    },
    "executionInfo": {
     "elapsed": 16553,
     "status": "ok",
     "timestamp": 1758289227332,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "mAOxnnV1Mzb-",
    "outputId": "09bc0ed3-a039-4c2d-853c-037fc79dcb42"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53480911bae343fc9a60587dad03e147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6541d1219684ab2ac79f1d573b81126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb8c5a4a3c54003b18cdb8c90f7898c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c55f44bcd949f09429f6096c9371f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be5b37c2d984f768e910f31a8f8d665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline(\"text2text-generation\", model=\"t5-base\")\n",
    "\n",
    "context = \"T5 is a transformer model created by Google for NLP tasks.\"\n",
    "question = \"Who created T5?\"\n",
    "\n",
    "output = qa_model(\"question: \" + question + \" context: \" + context)\n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uA_cjCpjOSst"
   },
   "source": [
    "**4. Multi-Language Translator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1989,
     "status": "ok",
     "timestamp": 1758289229335,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "8rUXzNBLOVCz",
    "outputId": "4a151c15-ec7c-491d-a210-acee5daccff5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie sind Sie?\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"text2text-generation\", model=\"t5-base\")\n",
    "\n",
    "sentence = \"How are you?\"\n",
    "output = translator(\"translate English to German: \" + sentence)\n",
    "print(output[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7731,
     "status": "ok",
     "timestamp": 1758289237112,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "8BlbUhmqP-C7",
    "outputId": "7f822f0d-71c9-4872-d663-d7647f181184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11335,
     "status": "ok",
     "timestamp": 1758289248450,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "AMdNJe-IOnaM",
    "outputId": "b462455f-6fb5-4696-ad03-ffc3e43012b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.6/413.6 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Finetune Google/T5-Small on Summarization\n",
    "!pip install -q datasets transformers accelerate transformers[sentencepiece] sacrebleu rouge_score py7zr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1387,
     "status": "ok",
     "timestamp": 1758289249833,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "siX4rXsZTZVL"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset  # Load dataset\n",
    "import torch  # PyTorch tensors & GPU\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # Automatically picks the right tokenizer & model\n",
    "from transformers import DataCollatorForSeq2Seq  # Dynamic padding and batching\n",
    "from transformers import TrainingArguments, Trainer  # Training setup & loop\n",
    "from transformers import pipeline  # High-level API for easy inference\n",
    "import warnings  # Handle warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484,
     "referenced_widgets": [
      "ec0b6dbc688f4195950d033ef51e623b",
      "6cbf0e5207c6417f9ba046e055b0dcc7",
      "4d490f8368c6497abc834e1e43840841",
      "cef4b15ec0624e8f977cdd92b590a384",
      "33e8eefa2e074cf8a004a4ab0bd40ded",
      "3afb3e89ce194d778bac00eecc1ded73",
      "3fc75269cd0e4ad69030f9e71399195c",
      "64d572e2340044f5bda4a0195993a0d8",
      "58f2b8290d8e46edbc0e5efe7d4e8fa5",
      "ef04949376d6492a897409b4adacbe57",
      "b554367d50434d15bdcc959cbdc6cfc4",
      "68300b3ad74f4f63bd9b8aaca6c4ed66",
      "3942334b5784451dbb252b45005a5b50",
      "d20ff658c1f440cdb7909935c2b1eb24",
      "253ea00c42fc4908b44cc33723046a7f",
      "84457a359e1241b59d0d0c83bb1f9a0b",
      "253d36d94d5745e9bd42bbcabe023d6e",
      "8cdf2a46ddcb40aa974bccf6a17b2efc",
      "65d73bb6e0274634aa19254825f4ce76",
      "799d42aabe734b579e8c915c94c95386",
      "f943d6601f104b2ab2d03433f5798355",
      "53b65cca289d455e921543f57a73c282",
      "75707306ddc849ba8a9ca71c599e72b1",
      "79336cd94703400eaecfe9678f62077d",
      "2f888aae5e664bf1ad92521fa0ef802a",
      "2db62b1a6fae4179ba08a3237ce916ae",
      "9e70a1b469244ad794c4e3cebd198dcf",
      "0bf1f385f95b4fc797277582bf4bbfdb",
      "a19841d2b2d44c0eae04696160be41ae",
      "be4248a4d9f944f3935d5efb157fe890",
      "6d5dee71511744989460b13787418c18",
      "7c09c971e8dd41a09a28c48c850efb47",
      "edcfba0e94df4a68b85999d5bff77b2f",
      "e87951b3fa3348debcfdb15adce4b616",
      "19ea02e6b1794d25997c9cf94e5bb951",
      "95cc31c74a83417ebc5889a4a68c3d44",
      "72a612c1c586467294e25f61f55bf093",
      "6b42d7e6bfd848cf885693d938e17e48",
      "bca2f84c08d64f298a5bc0baf03d4f41",
      "35271cf5c8994f64aa1e9664857e3f32",
      "f40e607fbbca4377a0ad4c3f0c452b8f",
      "ad88e193e6a344f7bf501c08ef062edf",
      "d3bb1642ac124b1480e3ea641d9c67b2",
      "825312b53d6149d0b12f903544f2b26f",
      "7b44afb5fb4b47cb999b0798ef72e90f",
      "5ce945fc3b45489ba20734cf1fb0c9cc",
      "21384d313e8145d8ae32f71b497622b3",
      "cb0fc68459f64ea4aa8f030653d51237",
      "aada289df36045988cb36c276b310adc",
      "a2ce4c88963747a097e40ace6be377b4",
      "2e71f63d6b6e4f37ab1913326a2e2887",
      "0c245f804a24477e9851f62521d55861",
      "6d3c59736e9042439b0eea4ff8fe4694",
      "20cc1d9483c14fb88fc05918abb33000",
      "687a8c288e2246f18e228a95cea8ac80",
      "469fd0e505cb439e96afe9fcc21a7782",
      "fc0b0ca4fbb74865a6a3367dacfcc442",
      "f964776f765f4f6da78b643f5a4947e8",
      "6b363a1fc0324fe293fdf20c2adbc9ac",
      "a34e56cc98824ef9acc3cf0b30f6b6f0",
      "988f3cea4b4f4e91a5a8e72c38691a50",
      "6363adad7ceb4574b7b81132365b7f9e",
      "80e755e0a1b844f19676fd3011e30eef",
      "cd9d57f22d80452ca8c20c9c561e864e",
      "d9447cbb8f1d44d1bc294aa86947da11",
      "2a88a3d334a54822abfffa058f30f325",
      "013ea846907d4039b91e439b520de1a8",
      "1c19b84f10cb4d99abd71e8dedd23700",
      "0c14872f14664013aa601602a371aada",
      "723a3c896fe346d3b82dcd009dac9a93",
      "c926a913bde44a0dbf63477aa9b42eab",
      "a0ea1de984924a298c4af83b94e4caa0",
      "e73c0b6ddbd74599bd7e634207f91a5c",
      "a9850b0046d94a069f602b101e716915",
      "8b42d421cdd14b059dba887e93198936",
      "8752aaa8e5d1451ead9631bd3def5982",
      "a21b3f69471e4eab84e89149ef9a5ebf"
     ]
    },
    "executionInfo": {
     "elapsed": 5244,
     "status": "ok",
     "timestamp": 1758289255165,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "Cq_G14zrTyMn",
    "outputId": "437e5ec9-e6fb-45fe-8afc-ce4e350fd127"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0b6dbc688f4195950d033ef51e623b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68300b3ad74f4f63bd9b8aaca6c4ed66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75707306ddc849ba8a9ca71c599e72b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87951b3fa3348debcfdb15adce4b616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b44afb5fb4b47cb999b0798ef72e90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469fd0e505cb439e96afe9fcc21a7782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013ea846907d4039b91e439b520de1a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14731\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"knkarthick/samsum\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "134586a3ba384bb7a330a3d849b9af46",
      "918d8b13744844b6bf3b7891514fd60a",
      "41e37d60ed864f3d91a271782973759d",
      "9d9f98da8bed40c0ac94ff250a40208f",
      "1af7bbb6b69d48db8a54e53b3a41edff",
      "c5b1800a63af45cebdf5fbe576712a6c",
      "0ade229246dd49a2ad9e88224ed25195",
      "5e9e7c358a0c428b9f510625bff78650",
      "563aa680749c4a379c99a3616b9af23e",
      "722ec2f4580e4ca69ad7c4516eefd5a5",
      "2bb9eadc10ac4cc3ba1e6da1efb1f867",
      "a0a3c88f9d5e432fbe80123037420541",
      "8700a704813945259086a7bcf4c30f82",
      "f2ba60cb33024c029d877a4a10a5dc1a",
      "05e19b14bf9f4e84a66e0d47e5e69592",
      "3f0fb9eb5049460b96602924f53ce847",
      "e079f8a33d2d4dbdab7b115af6024e58",
      "9cc532bd2dd1436d9b230e2910ea6c72",
      "71b690dd758248e19f4809b03f42cc7f",
      "c1592d4f6324438ebb910f48794cdecc",
      "1a1e7419d999457cbeb5b9079fad73ef",
      "a1061cb2047948a78332ae602583c209",
      "c7d8e546143e4ae0ad3d788f8fd75e03",
      "f57245d31c264b2d95c154d743dbf079",
      "43ea175622dc4f1d96c37d71cce927c4",
      "3f6ffd9c30e1405eb3951d18a3aef759",
      "09a107f91e5a414bb207aef617e6bec9",
      "c373f6ebc0a340fb9577ba3bf32be05d",
      "ea41b58e44a44fa88f8618b8481197a1",
      "98b600ffb6494994a2ef6314f2575914",
      "c71985aec6ca476d85e8af2bc562235a",
      "ff6da3e301db4e93bd9796bdee6aec42",
      "073c30ce263f4404a46b9bee92290a73",
      "fd27607f3e804bee8e2ced13ae719823",
      "0a26b71863fd4a6b923ba24872c26eaa",
      "97cf63b489424e8e8b858a691f33f75d",
      "92b6273eb2504a578dffab348671a9dc",
      "c9e48e1e3497462c9ca913ae69fd0e38",
      "b9f7fd8f71ec46d1be43a3520f2fa6d0",
      "63496fce92524584ba0ff6b03929e883",
      "3f588139499547699bc1cfd0c6e4498f",
      "1dcc8fdb62884b91be814b2b6a0868a6",
      "7bb33088efcf48ce95c16e9bb20deca8",
      "867da770dc2847bc907f25f4d33a5365",
      "06efd1a3ac9444a79974fe6a9c5f6d56",
      "e848c88f5cf4496a97abd218aa4b5245",
      "281c6af9236f402bbbbe00ae60ed1c81",
      "2481328caed74c32a06bc9112a2affcf",
      "6b408eef4cc74231a8a692e148e32da3",
      "224314dad18f4177b10da3662aec9611",
      "b00a6f9d44424065b539268f4a9c5929",
      "53663d015f02496a8b92f95fdca1029a",
      "a24bec60edbd49feac3e0dfdae2fc9a2",
      "d7fe5daa940b47ffa9a2618aba61ceb4",
      "1ad0917cefb0406483e914023701d1c6",
      "f1c3081e49e14332b66a61dfc95f2c28",
      "ef42dd455d6944adabfd31b1b0cc93cc",
      "208efe0098df4684b5fe7522efd551b7",
      "901085c144bc44b492f6249c316cb9fa",
      "12381916e2de41c8ab0bdae074f06454",
      "d01ccd8021804ec69f9f877141eb00bb",
      "c3dc9f8e955742b6b772821f016dde22",
      "5a4d4e72207e435c829ab2cec922d063",
      "1f57c798adc14dfaae1e10f727fd42da",
      "83840031cb7c44ae84103f0e5e221a42",
      "b6aa2bed07d04bd1b8e6d0f2514cbd15"
     ]
    },
    "executionInfo": {
     "elapsed": 9526,
     "status": "ok",
     "timestamp": 1758289264712,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "Xtf0xHdLWRvT",
    "outputId": "e5f57a95-a2ee-40d5-df17-5b51f2f1dce8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134586a3ba384bb7a330a3d849b9af46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a3c88f9d5e432fbe80123037420541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d8e546143e4ae0ad3d788f8fd75e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd27607f3e804bee8e2ced13ae719823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06efd1a3ac9444a79974fe6a9c5f6d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c3081e49e14332b66a61dfc95f2c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpoint = \"t5-small\"  # ✅ You can also use \"google/flan-t5-base\", \"facebook/bart-base\", etc.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "fcde1750c5a2424a983ada8712116fcd",
      "b87835e6a8c34ad3b94dc464ce57b185",
      "f2bd1af0db1c4fde91b0bb78df76eeba",
      "10aa3589b4a3449e94143fb4f8de7536",
      "64d4d846e4154e83a83b10b64170aad2",
      "da34c4f5ce364c1f8a14cbe325246216",
      "9a167bcb0b564ddf8dba3929c9b3fcf1",
      "6c7506a5029e4b5bb9f73a085397f16c",
      "a4e5451778624543aa14f8c3e2cf96b3",
      "76584a2660e74a7496240236cad4f0ad",
      "ec666cb843b24cc9b6978fb2b39e464a",
      "a1c1c205a150405d9e3e791091f4b44b",
      "451fb763a76a496d89809f21bb824e14",
      "dc81fe297cbd4e9d98ca6f68d4675025",
      "8ef0aac75d054e5ca958ed928862f7f0",
      "607d3e17e6e94360af5f00a5779252df",
      "358fe4cb084b4e44a2441cad011ef8f8",
      "3defcfe47caf4f689004897e6c23e771",
      "97e8b94ff92e4e8697d5b85d919feebd",
      "becd63b4873e483493bf5db9fce9b950",
      "be54a7a79451410dac7ea725ee9a5b48",
      "9101378c9f294edf8feda1dddfee0f07",
      "b6ad3a524a95436087d38f93f3b55532",
      "a6761eea83094423ba3b848d333c8251",
      "0c99269f5a7b4e5a810e21c33658ac6a",
      "4ce3b808fed841a5a5fba3ea893c743e",
      "9eb37f0e73714f85abf471fe228ff9de",
      "5fc46b90506d46be92a4be90d8bc9d0d",
      "555380cde315461a8f57b57dbbf89fd3",
      "bcc255963fb8412c8fa032ba1459dd6a",
      "e83fe65cbbcd44a08ed066c79a7da644",
      "fbca688a363543cfb10e330a8079fe87",
      "bade9773ecdd474085e5c82d46fff9cc"
     ]
    },
    "executionInfo": {
     "elapsed": 15024,
     "status": "ok",
     "timestamp": 1758289279727,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "YyTLT1XIUFlY",
    "outputId": "35672cda-f660-4a95-d67c-74f993867c0e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcde1750c5a2424a983ada8712116fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14731 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c1c205a150405d9e3e791091f4b44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/818 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ad3a524a95436087d38f93f3b55532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the Dataset\n",
    "\n",
    "def tokenize_content(data):\n",
    "    dialogues = data[\"dialogue\"]\n",
    "    summaries = data[\"summary\"]\n",
    "\n",
    "    inputs = [\"summarize: \" + d if d else \"summarize: \" for d in dialogues]\n",
    "    targets = [s if s else \"\" for s in summaries]\n",
    "\n",
    "    input_encoding = tokenizer(inputs, max_length=1024, truncation=True, padding=\"max_length\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encoding = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_encoding[\"input_ids\"],\n",
    "        \"attention_mask\": input_encoding[\"attention_mask\"],\n",
    "        \"labels\": target_encoding[\"input_ids\"],\n",
    "    }\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_content, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 111,
     "status": "ok",
     "timestamp": 1758289279844,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "EjT4IKH5WmFp"
   },
   "outputs": [],
   "source": [
    "# Setup Data Collator\n",
    "seq2seq_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"t5-samsum-model\",              # Where to save the model\n",
    "    num_train_epochs=1,                        # Number of training passes over data\n",
    "    per_device_train_batch_size=1,             # Samples per GPU during training\n",
    "    per_device_eval_batch_size=1,              # Samples per GPU during evaluation\n",
    "    warmup_steps=500,                          # Gradually increase LR for first 500 steps\n",
    "    weight_decay=0.01,                         # Regularization to prevent overfitting\n",
    "    logging_steps=10,                          # Log training metrics every 10 steps\n",
    "    eval_steps=500,                            # Run evaluation every 500 steps\n",
    "    save_steps=1e6,                            # Disable auto-saving during training\n",
    "    gradient_accumulation_steps=16,            # Accumulate gradients for larger batch effect\n",
    "    report_to=\"none\"                           # Disable logging to external tools\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=seq2seq_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1598432,
     "status": "ok",
     "timestamp": 1758290878282,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "7D4yPWsbXEws",
    "outputId": "90e80225-d455-4451-d23d-4d3c4c1ece53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='921' max='921' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [921/921 26:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>12.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>11.781600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>11.847000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>11.138300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>10.422600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>9.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>8.798600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>8.154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>7.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.498100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.575900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.656400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.378200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.168600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.973200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.887300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.851000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.760700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.739300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.636800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.647100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.594900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.581200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.562600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.566300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.528600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.479000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.515900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.564900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.528200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.527300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.523600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.531100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.466800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.517800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.507500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.456300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.459500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.485100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.518600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.483700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.479600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.421200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.483300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.458400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.485300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.475600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.494900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.465700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.463800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.497400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.426300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.481400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.507100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.513600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.483700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.516600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.498200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.433200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=921, training_loss=1.6627551675748877, metrics={'train_runtime': 1597.8277, 'train_samples_per_second': 9.219, 'train_steps_per_second': 0.576, 'total_flos': 3987440154968064.0, 'train_loss': 1.6627551675748877, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4475,
     "status": "ok",
     "timestamp": 1758290882769,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "B3roTEMCXNBn",
    "outputId": "339229b5-40fb-49f6-fa8b-8ae1457a1809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t5_samsum_tokenizer/tokenizer_config.json',\n",
       " 't5_samsum_tokenizer/special_tokens_map.json',\n",
       " 't5_samsum_tokenizer/spiece.model',\n",
       " 't5_samsum_tokenizer/added_tokens.json',\n",
       " 't5_samsum_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Save Model & Tokenizer\n",
    "model.save_pretrained(\"t5_samsum_finetuned_model\")\n",
    "tokenizer.save_pretrained(\"t5_samsum_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 921,
     "status": "ok",
     "timestamp": 1758290883699,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "VIHUZ_z2XTsE",
    "outputId": "372f57f0-cd1a-4554-b1e6-3c3bac01e275"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "#  Reload & Setup for Inference\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5_samsum_tokenizer\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5_samsum_finetuned_model\")\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "# No manual tokenization, no manual model.generate() — it abstracts all that under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1758290883758,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "xayQhGJRXrik"
   },
   "outputs": [],
   "source": [
    "#  Test Sample Dialogue (Luffy & Naruto)\n",
    "sample_text = '''Luffy: Naruto! You won the ramen eating contest again?! That’s your fifth win this month!\n",
    "\n",
    "Naruto: Believe it, Luffy! Ichiraku’s secret menu is my new training ground. Gotta keep up the chakra and the appetite!\n",
    "\n",
    "Luffy: Haha! I like that! I trained by eating 20 meat-on-the-bone last night. Zoro thought I was insane.\n",
    "\n",
    "Naruto: Bro, I’ve fought Akatsuki, and even I think that’s dangerous. What’s next? Competing with Goku?\n",
    "\n",
    "Luffy: Maybe! But first I wanna become the Pirate King. Then I’ll eat ramen on the moon!\n",
    "\n",
    "Naruto: You sure talk big, rubber boy. But I respect that. Becoming Hokage wasn’t easy either.\n",
    "\n",
    "Luffy: We’re kinda the same, huh? Chasing dreams, fighting crazy villains, making loyal friends.\n",
    "\n",
    "Naruto: True that. Though I don’t have a reindeer doctor or a skeleton with an afro.\n",
    "\n",
    "Luffy: And I don’t have a giant fox inside me. We’re even!\n",
    "\n",
    "Naruto: Hey, wanna team up for a mission? I heard there’s a lost treasure in the Hidden Mist village.\n",
    "\n",
    "Luffy: Treasure?! I’m in! Let’s go find it, and maybe snack along the way.\n",
    "\n",
    "Naruto: Deal. I’ll bring the kunai, you bring the appetite.\n",
    "\n",
    "Luffy: This is gonna be epic! Let's GO!!!\n",
    "\n",
    "Naruto: Dattebayo!!!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "executionInfo": {
     "elapsed": 1747,
     "status": "ok",
     "timestamp": 1758290885513,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "d0NNhRc3XvMb",
    "outputId": "41952de0-c5c5-414c-ae59-7f0ddac08c09"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Summary:** Luffy won the ramen eating contest again this month. Luffy has fought Akatsuki, and he will compete with Goku. Naruto will bring the kunai."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Show the Summary Output\n",
    "from IPython.display import Markdown, display\n",
    "result = summarizer(sample_text, max_length=100, min_length=30, do_sample=False) ## do_sampilng = False means Use greedy decoding (no randomness); always returns same result\n",
    "display(Markdown(f\"**Summary:** {result[0]['summary_text']}\"))\n",
    "# result format -->> [{'summary_text': 'Here is the generated summary.'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51441,
     "status": "ok",
     "timestamp": 1758291827049,
     "user": {
      "displayName": "M Aqeel Awan",
      "userId": "00217619579415678503"
     },
     "user_tz": -300
    },
    "id": "fkeGiX8qWsWz",
    "outputId": "60b7b02c-759d-4838-a7d8-cada294bc290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nbformat\n",
    "\n",
    "# Get current notebook name (Colab workaround)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')  # Optional if you're working from Drive\n",
    "\n",
    "# Replace with your actual notebook path\n",
    "notebook_path = '/content/drive/MyDrive/Colab Notebooks/imdb sentiment classification using RNN,LSTM,GRU.ipynb'  # Update this\n",
    "cleaned_path = '/content/imdb_sentiment_classification_using_RNN_LSTM_GRU.ipynb'\n",
    "\n",
    "# Load and clean notebook\n",
    "with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "if 'widgets' in nb['metadata']:\n",
    "    print(\"Removing metadata.widgets...\")\n",
    "    del nb['metadata']['widgets']\n",
    "\n",
    "# Save cleaned notebook\n",
    "with open(cleaned_path, 'w', encoding='utf-8') as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "print(f\"Cleaned notebook saved to: {cleaned_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO9cnKnotmVR9eVm+5LaXik",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
