{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMefTgbNlEUX9QlV0pr/CHE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import spacy\n","!python -m spacy download en_core_web_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPNozmOIdvGH","executionInfo":{"status":"ok","timestamp":1753771258756,"user_tz":-300,"elapsed":6650,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"cfdd8d3b-f22c-461b-8f5a-f04e74271f58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["# Load English tokenizer, tagger, parser and NER\n","nlp = spacy.load(\"en_core_web_sm\")\n","# Process whole documents\n","text = (\"\"\"Since you're methodical and focused on scalable NLP pipelines,\n","        spaCy might be your best ally for production-ready tasks.\n","        But if you're exploring linguistic theory\n","        or building custom tokenizers, NLTK still has its charm.\"\"\")\n","doc = nlp(text)"],"metadata":{"id":"aRTsPCMSdwzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Analyze syntax\n","print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n","print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n","\n","# Find named entities, phrases and concepts\n","for entity in doc.ents:\n","    print(entity.text, entity.label_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqQHcSIJeM13","executionInfo":{"status":"ok","timestamp":1753771259309,"user_tz":-300,"elapsed":28,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"d1342e5c-ac7e-4938-a3da-7f5cee160c68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Noun phrases: ['you', 'scalable NLP pipelines', 'your best ally', 'production-ready tasks', 'you', 'linguistic theory', 'custom tokenizers', 'NLTK', 'its charm']\n","Verbs: ['focus', 'explore', 'build', 'have']\n","NLP ORG\n","NLTK ORG\n"]}]},{"cell_type":"markdown","source":["# practice"],"metadata":{"id":"qVNIrV0Kep4-"}},{"cell_type":"code","source":["nlp.pipe_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKOgcNmMenv4","executionInfo":{"status":"ok","timestamp":1753771272274,"user_tz":-300,"elapsed":13,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"99513722-e804-4f4f-f341-75dda33d9e43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# checking pipe lines\n","doc = nlp(text)\n","for token in doc:\n","  print(token, \" | \", token.pos_, \" | \", token.lemma_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"avUno1hBenjy","executionInfo":{"status":"ok","timestamp":1753771688667,"user_tz":-300,"elapsed":42,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"50a65ab7-fb2d-49be-e534-c39e8848f4c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Since  |  SCONJ  |  since\n","you  |  PRON  |  you\n","'re  |  AUX  |  be\n","methodical  |  ADJ  |  methodical\n","and  |  CCONJ  |  and\n","focused  |  VERB  |  focus\n","on  |  ADP  |  on\n","scalable  |  ADJ  |  scalable\n","NLP  |  PROPN  |  NLP\n","pipelines  |  NOUN  |  pipeline\n",",  |  PUNCT  |  ,\n","\n","          |  SPACE  |  \n","        \n","spaCy  |  NUM  |  spacy\n","might  |  AUX  |  might\n","be  |  AUX  |  be\n","your  |  PRON  |  your\n","best  |  ADJ  |  good\n","ally  |  NOUN  |  ally\n","for  |  ADP  |  for\n","production  |  NOUN  |  production\n","-  |  PUNCT  |  -\n","ready  |  ADJ  |  ready\n","tasks  |  NOUN  |  task\n",".  |  PUNCT  |  .\n","\n","          |  SPACE  |  \n","        \n","But  |  CCONJ  |  but\n","if  |  SCONJ  |  if\n","you  |  PRON  |  you\n","'re  |  AUX  |  be\n","exploring  |  VERB  |  explore\n","linguistic  |  ADJ  |  linguistic\n","theory  |  NOUN  |  theory\n","\n","          |  SPACE  |  \n","        \n","or  |  CCONJ  |  or\n","building  |  VERB  |  build\n","custom  |  NOUN  |  custom\n","tokenizers  |  NOUN  |  tokenizer\n",",  |  PUNCT  |  ,\n","NLTK  |  PROPN  |  NLTK\n","still  |  ADV  |  still\n","has  |  VERB  |  have\n","its  |  PRON  |  its\n","charm  |  NOUN  |  charm\n",".  |  PUNCT  |  .\n"]}]},{"cell_type":"code","source":["# explaning this PUNCT\n","spacy.explain(\"PUNCT\")    , spacy.explain(\"SCONJ\") , spacy.explain(\"ADP\"), spacy.explain(\"DET\"), spacy.explain(\"NUM\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-KoJus08KDc","executionInfo":{"status":"ok","timestamp":1753772121045,"user_tz":-300,"elapsed":30,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"58c19ce9-3f78-405f-9a3d-f031b6601f54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('punctuation',\n"," 'subordinating conjunction',\n"," 'adposition',\n"," 'determiner',\n"," 'numeral')"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# NER named entity recognition\n","for ent in doc.ents:\n","  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3YyQGqc9zlZ","executionInfo":{"status":"ok","timestamp":1753772277607,"user_tz":-300,"elapsed":22,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"68b2f1e6-ec1e-47b7-ff47-81096761465b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NLP  |  ORG  |  Companies, agencies, institutions, etc.\n","NLTK  |  ORG  |  Companies, agencies, institutions, etc.\n"]}]},{"cell_type":"code","source":["# doing above cell in beautiful way\n","from spacy import displacy\n","displacy.render(doc, style='ent')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"id":"grXwZASw-co3","executionInfo":{"status":"ok","timestamp":1753772959404,"user_tz":-300,"elapsed":107,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"dba569fe-0501-40d8-a695-6fc95342f313"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Since you're methodical and focused on scalable \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    NLP\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," pipelines,<br>        spaCy might be your best ally for production-ready tasks.<br>        But if you're exploring linguistic theory<br>        or building custom tokenizers, \n","<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n","    NLTK\n","    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n","</mark>\n"," still has its charm.</div></span>"]},"metadata":{}}]},{"cell_type":"code","source":["# creating the blank pipe line\n","\n","nlp=spacy.blank(\"en\")\n","doc=nlp.make_doc(text)\n","text=\"Hey! my name is asad. I am going to Lahore to buy 34 laptop.\"\n","# for token in doc:\n","#   print(token, \" | \", token.pos_, \" | \", token.lemma_)\n","nlp.pipe_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsD6PflkBUeu","executionInfo":{"status":"ok","timestamp":1753773415613,"user_tz":-300,"elapsed":59,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"f34a8c4b-9e3f-429f-9b58-cefe679adc93"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["# creating own pipe line\n","source_nlp= spacy.load(\"en_core_web_sm\")\n","nlp=spacy.blank(\"en\")\n","nlp.add_pipe(\"ner\", source=source_nlp)\n","nlp.pipe_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81xPvAKVCs0s","executionInfo":{"status":"ok","timestamp":1753774172860,"user_tz":-300,"elapsed":1029,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"38e72f25-b386-4411-ea4d-c7ef5c3340aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['ner']"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["doc=nlp(\"Hey! my name is asad. I am going to Lahore to buy 34 laptop.\")\n","# text=\"Hey! my name is asad. I am going to Lahore to buy 34 laptop.\"\n","for ent in doc.ents:\n","  print(ent.text, \" | \", ent.label_, \" | \", spacy.explain(ent.label_))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDXC0Y8dE7ly","executionInfo":{"status":"ok","timestamp":1753774428963,"user_tz":-300,"elapsed":66,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"9c808767-66b7-499a-daf0-12a9c44d6add"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Lahore  |  GPE  |  Countries, cities, states\n","34  |  CARDINAL  |  Numerals that do not fall under another type\n"]}]},{"cell_type":"markdown","source":["ADDING CUSTOM ATTRIBUTES"],"metadata":{"id":"L2GxlfeJB35Q"}},{"cell_type":"code","source":["import spacy\n","nlp=spacy.load(\"en_core_web_sm\")\n","doc=nlp(\"ability,popularity,bro,brah,similiarity,booking,laghing,eats, ate,having.\")\n","for token in doc:\n","  print(token, \" | \",token.lemma_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mygqjqF6B8iJ","executionInfo":{"status":"ok","timestamp":1753857364150,"user_tz":-300,"elapsed":1386,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"174cd085-0b2b-4a4b-c64e-b575bdbaf587"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ability  |  ability\n",",  |  ,\n","popularity  |  popularity\n",",  |  ,\n","bro  |  bro\n",",  |  ,\n","brah  |  brah\n",",  |  ,\n","similiarity  |  similiarity\n",",  |  ,\n","booking  |  booking\n",",  |  ,\n","laghing  |  laghing\n",",  |  ,\n","eats  |  eat\n",",  |  ,\n","ate  |  eat\n",",  |  ,\n","having  |  have\n",".  |  .\n"]}]},{"cell_type":"code","source":["import nltk\n","from nltk.stem import PorterStemmer\n","stemmer=PorterStemmer()\n","doc=nlp(\"ability,popularity,bro,brah,similiarity,booking,laghing,eats, ate,having.\")\n","for token in doc:\n","  print(token, \" | \",stemmer.stem(token.text))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTPz-d6uDG1x","executionInfo":{"status":"ok","timestamp":1753857697867,"user_tz":-300,"elapsed":49,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"ef7451cc-82a5-4eac-dae2-3c4dea65e6e8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ability  |  abil\n",",  |  ,\n","popularity  |  popular\n",",  |  ,\n","bro  |  bro\n",",  |  ,\n","brah  |  brah\n",",  |  ,\n","similiarity  |  similiar\n",",  |  ,\n","booking  |  book\n",",  |  ,\n","laghing  |  lagh\n",",  |  ,\n","eats  |  eat\n",",  |  ,\n","ate  |  ate\n",",  |  ,\n","having  |  have\n",".  |  .\n"]}]},{"cell_type":"code","source":["at=nlp.get_pipe(\"attribute_ruler\")\n","at.add([[{\"TEXT\":\"bro\"}],[{\"TEXT\":\"brah\"}]],{\"LEMMA\":\"brother\"})\n","doc=nlp(\"ability,popularity,bro,brah,similiarity,booking,laghing,eats, ate,having.\")\n","for token in doc:\n","  print(token, \" | \",token.lemma_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYMaCaboEPvd","executionInfo":{"status":"ok","timestamp":1753858401652,"user_tz":-300,"elapsed":78,"user":{"displayName":"Muhammad Shakir","userId":"05932839632612654057"}},"outputId":"8c6a63b1-ef63-4fc4-f5af-51c7a078f680"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["ability  |  ability\n",",  |  ,\n","popularity  |  popularity\n",",  |  ,\n","bro  |  brother\n",",  |  ,\n","brah  |  brother\n",",  |  ,\n","similiarity  |  similiarity\n",",  |  ,\n","booking  |  booking\n",",  |  ,\n","laghing  |  laghing\n",",  |  ,\n","eats  |  eat\n",",  |  ,\n","ate  |  eat\n",",  |  ,\n","having  |  have\n",".  |  .\n"]}]}]}